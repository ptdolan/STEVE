{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "\"\"\"\n",
    "# ## ## ## ## # ## ## ## ## ## ## ## ## #\n",
    "# ## ## ## ##  FUNCTIONS  # ## ## ## ## #\n",
    "# ## ## ## ## # ## ## ## ## ## ## ## ## #\n",
    "\"\"\"\n",
    "\n",
    "def readFiles(conFile,teFile,eveFile,piFile,clustFile,clustTable):\n",
    "    print(\"\\nReading Data...\")\n",
    "    conDF=pd.read_csv(conFile,sep=\"\\t\",header=None)\n",
    "\n",
    "    teDF=pd.read_csv(teFile,sep=\"\\t\",header=None)\n",
    "    eveDF=pd.read_csv(eveFile,sep=\"\\t\")\n",
    "    piDF=pd.read_csv(piFile,sep=\",\",header=None)\n",
    "\n",
    "    piDF.columns=['piSeq','strand','contigInfo','piPos','complement']\n",
    "    piDF['contigPi']=[i[0] for i in piDF.contigInfo.str.split(\"|\")]\n",
    "    clustDF=pd.read_csv(clustFile,sep=\"\\t\",header=None)\n",
    "    clustInfo=pd.read_csv(clustTable,sep=\"\\t\",header=None,skiprows=59) #this is a real shit format.\n",
    "    print(\"done.\")\n",
    "\n",
    "    return(conDF,teDF,eveDF,piDF,clustDF,clustInfo)\n",
    "\n",
    "######\n",
    "# Progress bar\n",
    "# Adapted from: http://stackoverflow.com/questions/3173320/text-progress-bar-in-the-console\n",
    "######\n",
    "\n",
    "def progBar (iteration, total, prefix = '', suffix = '', decimals = 1, length = 40, fill = '|'):\n",
    "    \"\"\"\n",
    "    Call in a loop to create terminal progress bar\n",
    "    @params:\n",
    "        iteration   - Required  : current iteration (Int)\n",
    "        total       - Required  : total iterations (Int)\n",
    "        prefix      - Optional  : prefix string (Str)\n",
    "        suffix      - Optional  : suffix string (Str)\n",
    "        decimals    - Optional  : positive number of decimals in percent complete (Int)\n",
    "        length      - Optional  : character length of bar (Int)\n",
    "        fill        - Optional  : bar fill character (Str)\n",
    "    \"\"\"\n",
    "    percent = (\"{0:.\" + str(decimals) + \"f}\").format(100 * (iteration / float(total)))\n",
    "    filledLength = int(length * iteration // total)\n",
    "    bar = fill * filledLength + '-' * (length - filledLength)\n",
    "    sys.stdout.write('\\r%s |%s| %s%% %s' % (prefix, bar, percent, suffix))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    # Print New Line on Complete\n",
    "    if iteration == total:\n",
    "        print()\n",
    "\n",
    "################\n",
    "# generates dataframe of piRNA coordinates, counts, and index.\n",
    "################\n",
    "\n",
    "def piFrame(piSel,contig):\n",
    "    piSel,piCounts=np.unique(piSel,return_counts=True)\n",
    "    piF=pd.DataFrame({\"piSel\":piSel,\"piCounts\":piCounts,\"contig\":contig})\n",
    "    return(piF)\n",
    "\n",
    "def generateInts(selectS,selectE): #generates the int numpy arrays for comparison.\n",
    "    n=0\n",
    "    x=0\n",
    "    intList=[]\n",
    "    #print(selectS)\n",
    "    if len(selectS)>0:\n",
    "        for i in selectS:\n",
    "            if x==0:\n",
    "                intList=np.arange(i,selectE[n]+1,1)\n",
    "                x=1\n",
    "            else:\n",
    "                inter=np.arange(i,selectE[n]+1,1)\n",
    "                intList=np.concatenate((intList,inter))\n",
    "            n+=1\n",
    "\n",
    "    Sites,Counts=np.unique(intList,return_counts=True) #super handy function for counting number of mapped elements.\n",
    "    return(Sites,Counts)\n",
    "\n",
    "################\n",
    "# By Contig Analysis of Eves and piRNAs\n",
    "################\n",
    "def contiganalysis(piDF,eveDF,teDF):\n",
    "    print(\"\\nBy-Contig Analysis...\")\n",
    "\n",
    "#piRNAs\n",
    "    startsPi=piDF[3].values\n",
    "    endsPi=startsPi #Just a single Nt (5' start position)\n",
    "    contigPi=piDF['contigPi'].values\n",
    "\n",
    "#TEs\n",
    "    contigs=teDF[0].values\n",
    "    starts=teDF[1].values\n",
    "    ends=teDF[2].values\n",
    "\n",
    "#EVEs\n",
    "    startEVE=eveDF['EVEstart'].values\n",
    "    endEVE=eveDF['EVEend'].values\n",
    "    contigEVE=eveDF['ContigEVE'].values\n",
    "\n",
    "    ucontigs=np.unique(contigs,return_counts=True)\n",
    "    outputDF=pd.DataFrame()\n",
    "    l=len(ucontigs)\n",
    "    for C in ucontigs.iteritems():\n",
    "        progBar(C[0],l)\n",
    "        contigInfo=conDF.loc[conDF[0]==C,1]\n",
    "        selectSte=starts[contigs==c]\n",
    "        selectEte=ends[contigs==c]\n",
    "        selectSeve=startEVE[contigEVE==c]\n",
    "        selectEeve=endEVE[contigEVE==c]\n",
    "        selectSpi=np.array(startsPi[contigPi==c])\n",
    "        selectEpi=endsPi[contigPi==c]\n",
    "\n",
    "        #print(\"Generating Intervals...\")\n",
    "        eveSites,eveCounts=generateInts(selectSeve,selectEeve)\t#generates the integer lists for comparison\n",
    "        teSites,teCounts=generateInts(selectSte,selectEte)\n",
    "        piSites,piCounts=generateInts(selectSpi,selectEpi)\n",
    "        piStats=pd.DataFrame({\"piSites\":piSites,\"piCounts\":piCounts})\n",
    "\n",
    "        intersection=np.intersect1d(eveSites,teSites)\n",
    "        piintersection=np.intersect1d(eveSites,piStats['piSites'])\n",
    "\n",
    "        selCount=piStats.loc[piStats['piSites'].isin(piintersection),'piCounts']\n",
    "        #print(selCount)\n",
    "        piReads=np.sum(piCounts)\n",
    "        piReadsEVE=np.sum(selCount)\n",
    "        outputDFlist=pd.DataFrame({'contig':c,'length':contigInfo,'teSites':len(teSites),'eveSites':len(eveSites),\"eveTEoverlap\":len(intersection),\"piReads\":piReads,\"piEVEReads\":piReadsEVE,\"piSites\":len(piSites),\"piEVEoverlap\":len(piintersection)})\n",
    "        outputDFlist[\"teProp\"]=outputDFlist['teSites']/outputDFlist['length']\n",
    "        outputDFlist[\"eveTEProp\"]=outputDFlist['eveTEoverlap']/outputDFlist['eveSites']\n",
    "        outputDFlist[\"pi/eveProp\"]=outputDFlist['piEVEoverlap']/outputDFlist['eveSites']\n",
    "        outputDFlist[\"eve/piProp\"]=outputDFlist['piEVEoverlap']/outputDFlist['piSites']\n",
    "        outputDFlist[\"piReads/EVEProp\"]=outputDFlist['piEVEReads']/outputDFlist['piReads']\n",
    "        outputDF=pd.concat([outputDF,outputDFlist])\n",
    "        print(len(outputDF))\n",
    "        return(outputDF)\n",
    "\n",
    "#######################\n",
    "# By EVE analysis of piRNAs\n",
    "#######################\n",
    "def EVEanalysis(piDF,eveDF,teDF,TEtotal):\n",
    "    print(\"\\nby-EVE analysis...\")\n",
    "    allFrames=pd.DataFrame()\n",
    "    allStats=pd.DataFrame()\n",
    "    piTotal=len(piDF)\n",
    "    l=len(eveDF)\n",
    "    for i in eveDF.iterrows():\n",
    "        progBar(i[0],l)\n",
    "        contig=i[1]['ContigEVE']\n",
    "        family=i[1]['family']\n",
    "        species=i[1]['species']\n",
    "        ID=i[1]['EVEdescription']\n",
    "        piSel=piDF.loc[piDF.contigPi==contig,'piPos']\n",
    "        interval=np.arange(i[1][\"EVEstart\"],i[1][\"EVEend\"]+1,1) #EVE interval positions array\n",
    "        piF=piFrame(piSel,contig)\n",
    "        allFrames=pd.concat([allFrames,piF])\n",
    "        piEVEinter=np.intersect1d(piF['piSel'],interval)\n",
    "        countVector=piF['piCounts'].loc[piF['piSel'].isin(piEVEinter).values]\n",
    "        piEVEreads=countVector\n",
    "        piEVEoverlap=len(piEVEinter)\n",
    "        piStats=pd.DataFrame({\"ID\":ID,\"piPos\":[len(piSel)],\"piReads\":[piF.piCounts.sum()],\"piEVEreads\":[np.sum(piEVEreads)],\"piEVEPos\":[piEVEoverlap],\"family\":[family],\"species\":[species],\"EVEPos\":[len(interval)],\"contig\":contig,\"piTotal\":[piTotal]})\n",
    "        allStats=pd.concat([allStats,piStats])\n",
    "    \n",
    "    allStats[\"piReadsPerPos\"]=allStats['piEVEreads']/allStats['EVEPos']\n",
    "    allStats[\"piEVEProp\"]=allStats['piEVEreads']/allStats['piTotal']\n",
    "    allStats[\"EVEpiCover\"]=allStats['piEVEPos']/allStats['EVEPos']\n",
    "\n",
    "    allStats['piPerTESite']=allStats['piTotal']/TEtotal\n",
    "    allStats['piPerSite']=allStats['piTotal']/1723952533\n",
    "    allStats['propGenome']=allStats['EVEPos']/1723952533\n",
    "    allStats['enrichGenome']=allStats['piEVEProp']/allStats['propGenome']\n",
    "    allStats['enrichGenome']=allStats['piEVEProp']/allStats['propGenome']\n",
    "\n",
    "    teDF['length']=(teDF[1]-teDF[2]).abs()\n",
    "    return(allStats)\n",
    "\n",
    "############################\n",
    "# by piCluster ANALYSIS OF EVEs and piRNAs\n",
    "############################\n",
    "def piClustanalysis(piDF,clustDF,eveDF,TEtotal):\n",
    "    print(\"\\nby-Cluster analysis...\")\n",
    "    allFrames=pd.DataFrame()\n",
    "    allStatsClust=pd.DataFrame()\n",
    "    piTotal=len(piDF)\n",
    "    l=len(clustDF)\n",
    "    for i in clustDF.iterrows():\n",
    "        progBar(i[0],l)\n",
    "        contig=i[1][0]\n",
    "        clusterS=i[1][1]\n",
    "        clusterE=i[1][2]\n",
    "        clustInterval=np.arange(clusterS,clusterE+1,1)\n",
    "        piSel=piDF.loc[piDF.contigPi==contig,'piPos'] #piSel: piRNAs mapping to a given contig\n",
    "#        pSel.columns=['','','','']\n",
    "        piF=piFrame(piSel,contig)\n",
    "        allFrames=pd.concat([allFrames,piF])\n",
    "        piClustinter=np.intersect1d(piF['piSel'],clustInterval)\n",
    "        piClustreads=piF.loc[piF['piSel'].isin(piClustinter).values,'piCounts']\n",
    "        eveSel=eveDF.loc[eveDF.ContigEVE==contig,:]\n",
    "        EVEhit=0\n",
    "        EVEtotal=eveSel.EVEdescription.count()\n",
    "        EVEClustOlen=0\n",
    "        ClustEVEpiOlen=0\n",
    "        ClustEVEpiOreads=0\n",
    "        EVEClustoverlapreads=0\n",
    "        EVEf=[]\n",
    "        if EVEtotal>0:\n",
    "            EVEfamily=eveSel.family\n",
    "            EVEspecies=eveSel.species\n",
    "            EVEID=eveSel.EVEdescription\n",
    "            for EVE in eveSel.iterrows():\n",
    "                EVEinterval=np.arange(EVE[1][\"EVEstart\"],EVE[1][\"EVEend\"]+1,1)\n",
    "                EVEClustoverlap=np.intersect1d(EVEinterval,clustInterval)   #cluster-EVE overlap\n",
    "                EVEClustoverlapreads+=piF.loc[piF['piSel'].isin(EVEClustoverlap).values,'piCounts'].sum()\n",
    "                EVEClustOlen+=len(EVEClustoverlap)\n",
    "                ClustEVEpioverlap=np.intersect1d(EVEClustoverlap,piClustinter)\n",
    "                ClustEVEpiOlen+=len(ClustEVEpioverlap)\n",
    "                ClustEVEpiOreads+=piF.loc[piF['piSel'].isin(np.intersect1d(EVEClustoverlap,piClustinter)).values,'piCounts'].sum()\n",
    "                if len(EVEClustoverlap)>0:\n",
    "                    F=EVE[1]['family']\n",
    "                    EVEf.append(str(F))\n",
    "                    EVEhit+=1\n",
    "                    #print(EVEhit)\n",
    "        eveF=len(set(EVEf))\n",
    "        clustEVEcover=EVEClustOlen/i[1][5]\n",
    "        index=i[0]\n",
    "        #print(index)\n",
    "    allStatsClust=pd.concat([allStatsClust,pd.DataFrame({\"piTotal\":[piTotal],\"EVEhits\":[EVEhit],\"EVEfamilies\":[eveF],\"EVE-ClusterOverlap\":[EVEClustOlen],\"ClusterEVEpiOverlap\":[ClustEVEpiOlen],\"ClusterEVEpiReads\":[ClustEVEpiOreads],\"clusterEVEcoverage\":[clustEVEcover],\"piClust_reads\":[piClustreads.sum()],\"piClust_piSites\":[len(piClustinter)]},index=[i[0]])])\n",
    "    return(allStatsClust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading Data...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-0e4bf8ffe09c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#       READ in each file as a panda DF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mconDF\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mteDF\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meveDF\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpiDF\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclustDF\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclustInfo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreadFiles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconFile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mteFile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meveFile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpiFile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclustFile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclustTable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;31m#   Individual comparison scripts. Generate a pdDF and write to CSV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-62-73c1a91aabb3>\u001b[0m in \u001b[0;36mreadFiles\u001b[0;34m(conFile, teFile, eveFile, piFile, clustFile, clustTable)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mteDF\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mteFile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0meveDF\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meveFile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mpiDF\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpiFile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mpiDF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'piSeq'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'strand'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'contigInfo'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'piPos'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'complement'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ptdolan/miniconda3/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    560\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ptdolan/miniconda3/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m _parser_defaults = {\n",
      "\u001b[0;32m/Users/ptdolan/miniconda3/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    813\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'skip_footer not supported for iteration'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 815\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'as_recarray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ptdolan/miniconda3/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1312\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1313\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1314\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1315\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandaGenome as PG\n",
    "\n",
    "##########################################\n",
    "#\tDefine input file paths.\n",
    "##########################################\n",
    "conFile= \"/Users/ptdolan/Research/EVEsAndpiRNA/Frozen_Data/Aag2_assembly/Aag2_Contigs.fa.fai\"\n",
    "teFile=\"/Users/ptdolan/Research/EVEsAndpiRNA/Frozen_Data/Aag2_assembly/Aag2_Contigs_TEs.bed\"\n",
    "eveFile=\"/Users/ptdolan/Research/EVEsAndpiRNA/Frozen_Data/Aag2_assembly/Aag2_Contigs_EVEs_sorted.bed_withTaxonomy.txt\"\n",
    "piFile=\"/Users/ptdolan/Research/EVEsAndpiRNA/Frozen_Data/Aag2_assembly/Aag2_piRNAs/I234_dsFluc-B_Aag2-PB.map_piRNA.csv\"\n",
    "clustFile=\"/Users/ptdolan/Research/EVEsAndpiRNA/Frozen_Data/proTRAC_piRNAs.map_2016y11m1d22h53m3s/Aag2_piClusters.bed\"\n",
    "clustTable=\"/Users/ptdolan/Research/EVEsAndpiRNA/Frozen_Data/proTRAC_piRNAs.map_2016y11m1d22h53m3s/results.table\"\n",
    "\n",
    "#\tREAD in each file as a panda DF\n",
    "conDF,teDF,eveDF,piDF,clustDF,clustInfo=readFiles(conFile,teFile,eveFile,piFile,clustFile,clustTable)\n",
    "#   Individual comparison scripts. Generate a pdDF and write to CSV\n",
    "\n",
    "# contigOut=PG.contiganalysis(piDF,eveDF,teDF,TEtotal)\n",
    "# contigOut.to_csv(\"EVE_TE_pi_Analysis_byContig.csv\")\n",
    "# TEtotal = contigOut.teSites.sum()\n",
    "\n",
    "eveOut=PG.EVEanalysis(piDF,eveDF,teDF,TEtotal=926471910)\n",
    "eveOut.to_csv(\"EVE_TE_pi_Analysis_byEVE.csv\")\n",
    "\n",
    "clustOut=PG.piClustanalysis(piDF,clustDF,eveDF,TEtotal=926471910)\n",
    "clustOut.to_csv(\"EVE_TE_pi_Analysis_byClust.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
